{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Named entity recognition\n",
    "\n",
    "Построить модель для обнаружения и классификации именованных сущностей (named entities). На базе корпуса CoNLL 2002.  \n",
    "\n",
    "Используйте в своем решении ансамбли над решающими деревьями: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost) \n",
    "Tutorials:  \n",
    "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
    "1. https://github.com/catboost/tutorials \n",
    "\n",
    "\n",
    "Чем больше baseline'ов вы превзойдете, тем выше ваша оценка\n",
    "Метрика качества f1 (f1_macro) (чем выше, тем лучше)\n",
    " \n",
    "baseline 1: 0.0604      random labels  \n",
    "baseline 2: 0.3966      PoS features + logistic regression  \n",
    "baseline 3: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
    "\n",
    "! Your results must be reproducible. Если ваша модель - стохастическая, то вы явно должны задавать все seed и random_state в параметрах моделей   \n",
    "\n",
    "bonus, think about:  \n",
    "1. How can you exploit that words belong to some sentence?\n",
    "2. Why we selected f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anna_zueva_v/anaconda3/lib/python3.5/site-packages/sklearn/utils/fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SEED=1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  next-next-pos next-next-word next-pos      next-word  pos    prev-pos  \\\n",
       "0           NNS  demonstrators       IN             of  NNS  __START1__   \n",
       "1           VBP           have      NNS  demonstrators   IN         NNS   \n",
       "2           VBN        marched      VBP           have  NNS          IN   \n",
       "3            IN        through      VBN        marched  VBP         NNS   \n",
       "4           NNP         London       IN        through  VBN         VBP   \n",
       "\n",
       "  prev-prev-pos prev-prev-word      prev-word  sentence_idx           word tag  \n",
       "0    __START2__     __START2__     __START1__           1.0      Thousands   O  \n",
       "1    __START1__     __START1__      Thousands           1.0             of   O  \n",
       "2           NNS      Thousands             of           1.0  demonstrators   O  \n",
       "3            IN             of  demonstrators           1.0           have   O  \n",
       "4           NNS  demonstrators           have           1.0        marched   O  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ner_short.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sentences\n",
    "df.sentence_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.852828\n",
       "B-geo    0.027604\n",
       "B-gpe    0.020935\n",
       "B-org    0.020247\n",
       "I-per    0.017795\n",
       "B-tim    0.016927\n",
       "B-per    0.015312\n",
       "I-org    0.013937\n",
       "I-geo    0.005383\n",
       "I-tim    0.004247\n",
       "B-art    0.001376\n",
       "I-gpe    0.000837\n",
       "I-art    0.000748\n",
       "B-eve    0.000628\n",
       "I-eve    0.000508\n",
       "B-nat    0.000449\n",
       "I-nat    0.000239\n",
       "Name: tag, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df.tag.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sentence length\n",
    "tdf = df.set_index('sentence_idx')\n",
    "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
    "df = tdf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# encode categorial variables\n",
    "le = LabelEncoder()\n",
    "df['pos'] = le.fit_transform(df.pos)\n",
    "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
    "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
    "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
    "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>London</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx  next-next-pos next-next-word  next-pos      next-word  pos  \\\n",
       "0           1.0             18  demonstrators         9             of   18   \n",
       "1           1.0             33           have        18  demonstrators    9   \n",
       "2           1.0             32        marched        33           have   18   \n",
       "3           1.0              9        through        32        marched   33   \n",
       "4           1.0             16         London         9        through   32   \n",
       "\n",
       "   prev-pos  prev-prev-pos prev-prev-word      prev-word           word tag  \\\n",
       "0        39             40     __START2__     __START1__      Thousands   O   \n",
       "1        18             39     __START1__      Thousands             of   O   \n",
       "2         9             18      Thousands             of  demonstrators   O   \n",
       "3        18              9             of  demonstrators           have   O   \n",
       "4        33             18  demonstrators           have        marched   O   \n",
       "\n",
       "   length  \n",
       "0      48  \n",
       "1      48  \n",
       "2      48  \n",
       "3      48  \n",
       "4      48  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 50155\n",
      "test 16719\n"
     ]
    }
   ],
   "source": [
    "# splitting\n",
    "y = LabelEncoder().fit_transform(df.tag)\n",
    "\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y, stratify=y, \n",
    "                                                            test_size=0.25,\n",
    "                                                            random_state=SEED,\n",
    "                                                            shuffle=True)\n",
    "print('train', df_train.shape[0])\n",
    "print('test', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# some wrappers to work with word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "   \n",
    "class Word2VecWrapper(TransformerMixin):\n",
    "    def __init__(self, window=5,negative=5, size=100, iter=100, is_cbow=False, random_state=SEED):\n",
    "        self.window_ = window\n",
    "        self.negative_ = negative\n",
    "        self.size_ = size\n",
    "        self.iter_ = iter\n",
    "        self.is_cbow_ = is_cbow\n",
    "        self.w2v = None\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def get_size(self):\n",
    "        return self.size_\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        X: list of strings\n",
    "        \"\"\"\n",
    "        sentences_list = [x.split() for x in X]\n",
    "        self.w2v = Word2Vec(sentences_list, \n",
    "                            window=self.window_,\n",
    "                            negative=self.negative_, \n",
    "                            size=self.size_, \n",
    "                            iter=self.iter_,\n",
    "                            sg=not self.is_cbow_, seed=self.random_state)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def has(self, word):\n",
    "        return word in self.w2v\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X: a list of words\n",
    "        \"\"\"\n",
    "        if self.w2v is None:\n",
    "            raise Exception('model not fitted')\n",
    "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.8 s, sys: 704 ms, total: 51.5 s\n",
      "Wall time: 21.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# here we exploit that word2vec is an unsupervised learning algorithm\n",
    "# so we can train it on the whole dataset (subject to discussion)\n",
    "\n",
    "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
    "\n",
    "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
    "w2v_cbow.fit(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# baseline 1 \n",
    "# random labels\n",
    "\n",
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('enc', OneHotEncoder()),\n",
    "    ('est', DummyClassifier(random_state=SEED)),\n",
    "])\n",
    "\n",
    "model.fit(df_train[columns], y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# baseline 2 \n",
    "# pos features + one hot encoding + logistic regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('enc', OneHotEncoder()),\n",
    "    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
    "                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
    "])\n",
    "\n",
    "model.fit(df_train[columns], y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy.sparse as sp\n",
    "\n",
    "embeding = w2v_cbow\n",
    "encoder_pos = OneHotEncoder()\n",
    "X_train = sp.hstack([\n",
    "    embeding.transform(df_train.word),\n",
    "    embeding.transform(df_train['next-word']),\n",
    "    embeding.transform(df_train['next-next-word']),\n",
    "    embeding.transform(df_train['prev-word']),\n",
    "    embeding.transform(df_train['prev-prev-word']),\n",
    "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']]),\n",
    "    df_train[['length', 'sentence_idx']]\n",
    "])\n",
    "X_test = sp.hstack([\n",
    "    embeding.transform(df_test.word),\n",
    "    embeding.transform(df_test['next-word']),\n",
    "    embeding.transform(df_test['next-next-word']),\n",
    "    embeding.transform(df_test['prev-word']),\n",
    "    embeding.transform(df_test['prev-prev-word']),\n",
    "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']]),\n",
    "    df_test[['length', 'sentence_idx']]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# baseline 3\n",
    "# use word2vec cbow embedding + baseline 2 + svm\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
    "                                    {'C': np.logspace(-4, 0, 5)}, \n",
    "                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберем значение параметра ```boosting_type```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of   9 | elapsed:   51.6s remaining:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'boosting_type': 'dart'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "\n",
    "params = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'goss']\n",
    "}\n",
    "\n",
    "gbm = lgb.LGBMClassifier(boosting_type='gbdt', objective='multiclass',\n",
    "                         num_class=17, verbose=2, save_binary=True, seed=SEED)\n",
    "\n",
    "grid = GridSearchCV(gbm, params, scoring='f1_macro', verbose=2, n_jobs=-1)\n",
    "grid.fit(df_train[columns + ['length']], y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_boosting_type</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.614552</td>\n",
       "      <td>3.465454</td>\n",
       "      <td>0.270666</td>\n",
       "      <td>0.359975</td>\n",
       "      <td>gbdt</td>\n",
       "      <td>{'boosting_type': 'gbdt'}</td>\n",
       "      <td>3</td>\n",
       "      <td>0.325514</td>\n",
       "      <td>0.429477</td>\n",
       "      <td>0.183395</td>\n",
       "      <td>0.238551</td>\n",
       "      <td>0.303083</td>\n",
       "      <td>0.411895</td>\n",
       "      <td>0.035523</td>\n",
       "      <td>0.343368</td>\n",
       "      <td>0.062385</td>\n",
       "      <td>0.086159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.707252</td>\n",
       "      <td>2.365002</td>\n",
       "      <td>0.529477</td>\n",
       "      <td>0.735086</td>\n",
       "      <td>dart</td>\n",
       "      <td>{'boosting_type': 'dart'}</td>\n",
       "      <td>1</td>\n",
       "      <td>0.550501</td>\n",
       "      <td>0.718046</td>\n",
       "      <td>0.520870</td>\n",
       "      <td>0.775735</td>\n",
       "      <td>0.517053</td>\n",
       "      <td>0.711478</td>\n",
       "      <td>0.143868</td>\n",
       "      <td>0.078751</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.028868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.640343</td>\n",
       "      <td>3.404577</td>\n",
       "      <td>0.271942</td>\n",
       "      <td>0.370197</td>\n",
       "      <td>goss</td>\n",
       "      <td>{'boosting_type': 'goss'}</td>\n",
       "      <td>2</td>\n",
       "      <td>0.398389</td>\n",
       "      <td>0.555278</td>\n",
       "      <td>0.300093</td>\n",
       "      <td>0.432263</td>\n",
       "      <td>0.117285</td>\n",
       "      <td>0.123048</td>\n",
       "      <td>0.346563</td>\n",
       "      <td>0.558897</td>\n",
       "      <td>0.116474</td>\n",
       "      <td>0.181833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score  \\\n",
       "0       8.614552         3.465454         0.270666          0.359975   \n",
       "1      23.707252         2.365002         0.529477          0.735086   \n",
       "2      11.640343         3.404577         0.271942          0.370197   \n",
       "\n",
       "  param_boosting_type                     params  rank_test_score  \\\n",
       "0                gbdt  {'boosting_type': 'gbdt'}                3   \n",
       "1                dart  {'boosting_type': 'dart'}                1   \n",
       "2                goss  {'boosting_type': 'goss'}                2   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0           0.325514            0.429477           0.183395   \n",
       "1           0.550501            0.718046           0.520870   \n",
       "2           0.398389            0.555278           0.300093   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.238551           0.303083            0.411895      0.035523   \n",
       "1            0.775735           0.517053            0.711478      0.143868   \n",
       "2            0.432263           0.117285            0.123048      0.346563   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.343368        0.062385         0.086159  \n",
       "1        0.078751        0.014950         0.028868  \n",
       "2        0.558897        0.116474         0.181833  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подберём значения параметров ```max_depth```, ```num_leaves``` и ```min_data_in_leaf``` (подбираем параметры отдельно от ```boosting_type```, поскольку перебор по сетке требует много ресурсов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  7.3min\n",
      "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed: 17.9min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': -1, 'min_data_in_leaf': 100, 'num_leaves': 150}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth': [-1, 10, 100],\n",
    "    'num_leaves': [31, 70, 150],\n",
    "    'min_data_in_leaf': [100, 500, 1000]\n",
    "}\n",
    "\n",
    "gbm = lgb.LGBMClassifier(boosting_type='dart', objective='multiclass',\n",
    "                         num_class=17, verbose=2, save_binary=True, seed=SEED)\n",
    "\n",
    "grid = GridSearchCV(gbm, params, scoring='f1_macro', verbose=2, n_jobs=-1)\n",
    "grid.fit(df_train[columns + ['length']], y_train)\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39299675138382106"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель с полученными параметрами, увеличив значение ```num_boost_round```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred(pred):\n",
    "    y_pred = []\n",
    "\n",
    "    for x in pred:\n",
    "        y_pred.append(np.argmax(x))\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "train 0.954533312953\n",
      "test 0.769650105597\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 17,\n",
    "    'num_leaves': 150,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'metric': 'multi_logloss',\n",
    "    'seed': SEED,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "\n",
    "gbm = lgb.train(params,\n",
    "                lgb.Dataset(df_train[columns + ['length']], y_train),\n",
    "                num_boost_round=1000)\n",
    "\n",
    "train_p = get_pred(gbm.predict(df_train[columns + ['length']]))\n",
    "test_p = get_pred(gbm.predict(df_test[columns + ['length']]))\n",
    "\n",
    "print('train', metrics.f1_score(y_train, train_p, average='macro'))\n",
    "print('test', metrics.f1_score(y_test, test_p, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 2 побит!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим в датасет ещё один признак -- номер предложения ```sentence_idx```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 46min 40s, sys: 9.08 s, total: 1h 46min 49s\n",
      "Wall time: 17min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "params1 = {\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 17,\n",
    "    'num_leaves': 150,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'metric': 'multi_logloss',\n",
    "    'seed': SEED,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "gbm1 = lgb.train(params1,\n",
    "                lgb.Dataset(df_train[columns + ['length', 'sentence_idx']], y_train),\n",
    "                num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.997000963031\n",
      "test 0.847599357398\n"
     ]
    }
   ],
   "source": [
    "train_p1 = get_pred(gbm1.predict(df_train[columns + ['length', 'sentence_idx']]))\n",
    "test_p1 = get_pred(gbm1.predict(df_test[columns + ['length', 'sentence_idx']]))\n",
    "\n",
    "print('train', metrics.f1_score(y_train, train_p1, average='macro'))\n",
    "print('test', metrics.f1_score(y_test, test_p1, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 3 побит!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим ```word2vec cbow embedding```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "params2 = {\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 17,\n",
    "    'num_leaves': 150,\n",
    "    'min_data_in_leaf': 100,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'metric': 'multi_logloss',\n",
    "    'seed': SEED,\n",
    "    'verbose': 1\n",
    "}\n",
    "\n",
    "gbm2 = lgb.train(params2,\n",
    "                lgb.Dataset(X_train, y_train),\n",
    "                num_boost_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.999591373653\n",
      "test 0.886729641668\n"
     ]
    }
   ],
   "source": [
    "train_p2 = get_pred(gbm2.predict(X_train))\n",
    "test_p2 = get_pred(gbm2.predict(X_test))\n",
    "\n",
    "print('train', metrics.f1_score(y_train, train_p2, average='macro'))\n",
    "print('test', metrics.f1_score(y_test, test_p2, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How can you exploit that words belong to some sentence?\n",
    "Этот признак может помочь при определении именных сущностей, состоящих из нескольких слов и соответственно находящихся рядом в одном предложении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why we selected f1 score with macro averaging as our classification quality measure? What other metrics are suitable?\n",
    "Используется метрика ```f1 score```, поскольку классы сильно не сбалансированы (класс ```'О'``` составляет целых 85% от всех остальных классов, а класс ```I-nat```, напротив, всего лишь 0.0002%). Если будет использоваться метрика ```accuracy```, то значение метрики будет высоким даже если всё будет предсказываться как ```'О'```. Мы могли бы также смотреть на ```precision-recall``` для каждого класса или использовать ```precision-recall macro-averaged```."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
